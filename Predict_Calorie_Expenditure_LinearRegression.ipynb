{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91716,"databundleVersionId":11893428,"sourceType":"competition"}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/omarhadf/predict-calorie-expenditure-linearregression?scriptVersionId=238779483\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-09T15:14:05.737108Z","iopub.execute_input":"2025-05-09T15:14:05.737391Z","iopub.status.idle":"2025-05-09T15:14:08.141711Z","shell.execute_reply.started":"2025-05-09T15:14:05.737369Z","shell.execute_reply":"2025-05-09T15:14:08.140721Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/playground-series-s5e5/sample_submission.csv\n/kaggle/input/playground-series-s5e5/train.csv\n/kaggle/input/playground-series-s5e5/test.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport datetime\nfrom scipy.stats import chi2_contingency\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression, SGDRegressor, TweedieRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_squared_log_error\nfrom sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor, StackingRegressor\n\n# Suppress warnings (optional)\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T15:14:08.143681Z","iopub.execute_input":"2025-05-09T15:14:08.144112Z","iopub.status.idle":"2025-05-09T15:14:11.127073Z","shell.execute_reply.started":"2025-05-09T15:14:08.144085Z","shell.execute_reply":"2025-05-09T15:14:11.125858Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/playground-series-s5e5/train.csv', index_col=[\"id\"])\ntest = pd.read_csv('/kaggle/input/playground-series-s5e5/test.csv')\nsubmission = pd.read_csv('/kaggle/input/playground-series-s5e5/sample_submission.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T15:14:11.128144Z","iopub.execute_input":"2025-05-09T15:14:11.128748Z","iopub.status.idle":"2025-05-09T15:14:12.618186Z","shell.execute_reply.started":"2025-05-09T15:14:11.128719Z","shell.execute_reply":"2025-05-09T15:14:12.617237Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T11:27:58.930687Z","iopub.execute_input":"2025-05-09T11:27:58.931016Z","iopub.status.idle":"2025-05-09T11:27:58.956194Z","shell.execute_reply.started":"2025-05-09T11:27:58.930978Z","shell.execute_reply":"2025-05-09T11:27:58.955403Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T11:27:58.956897Z","iopub.execute_input":"2025-05-09T11:27:58.957104Z","iopub.status.idle":"2025-05-09T11:27:58.969168Z","shell.execute_reply.started":"2025-05-09T11:27:58.957086Z","shell.execute_reply":"2025-05-09T11:27:58.968395Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train.describe(include = 'all')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T11:28:01.846716Z","iopub.execute_input":"2025-05-09T11:28:01.847668Z","iopub.status.idle":"2025-05-09T11:28:02.212482Z","shell.execute_reply.started":"2025-05-09T11:28:01.847631Z","shell.execute_reply":"2025-05-09T11:28:02.211612Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test.describe(include = 'all')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T11:28:02.234252Z","iopub.execute_input":"2025-05-09T11:28:02.234657Z","iopub.status.idle":"2025-05-09T11:28:02.363285Z","shell.execute_reply.started":"2025-05-09T11:28:02.234627Z","shell.execute_reply":"2025-05-09T11:28:02.362421Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sns.countplot(data=train, x='Sex')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T11:28:02.577712Z","iopub.execute_input":"2025-05-09T11:28:02.578017Z","iopub.status.idle":"2025-05-09T11:28:03.235189Z","shell.execute_reply.started":"2025-05-09T11:28:02.577991Z","shell.execute_reply":"2025-05-09T11:28:03.234394Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sns.countplot(data=test, x='Sex')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T11:28:08.152982Z","iopub.execute_input":"2025-05-09T11:28:08.153312Z","iopub.status.idle":"2025-05-09T11:28:08.398326Z","shell.execute_reply.started":"2025-05-09T11:28:08.153286Z","shell.execute_reply":"2025-05-09T11:28:08.397323Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_hist(df1, df2, num_cols):\n    for col in num_cols:\n        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n\n        # Left plot (train)\n        sns.histplot(df1[col], kde=True, ax=ax1)\n        ax1.set_title(f'Train - {col}')\n\n        # Right plot (test)\n        sns.histplot(df2[col], kde=True, ax=ax2)\n        ax2.set_title(f'Test - {col}')\n\n        plt.tight_layout()\n        plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T11:28:08.517868Z","iopub.execute_input":"2025-05-09T11:28:08.518189Z","iopub.status.idle":"2025-05-09T11:28:08.523864Z","shell.execute_reply.started":"2025-05-09T11:28:08.518164Z","shell.execute_reply":"2025-05-09T11:28:08.522707Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"num_col = ['Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp']\n\nplot_hist(train, test, num_col)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T11:28:11.426961Z","iopub.execute_input":"2025-05-09T11:28:11.427264Z","iopub.status.idle":"2025-05-09T11:28:40.75096Z","shell.execute_reply.started":"2025-05-09T11:28:11.427239Z","shell.execute_reply":"2025-05-09T11:28:40.750029Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T11:28:46.021983Z","iopub.execute_input":"2025-05-09T11:28:46.02228Z","iopub.status.idle":"2025-05-09T11:28:46.028013Z","shell.execute_reply.started":"2025-05-09T11:28:46.022257Z","shell.execute_reply":"2025-05-09T11:28:46.027233Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure()\nsns.histplot(train['Calories'], kde=True, label='Calories')\n\n\nplt.title(\"Calories hist\")\n\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T11:28:46.962816Z","iopub.execute_input":"2025-05-09T11:28:46.963107Z","iopub.status.idle":"2025-05-09T11:28:50.498069Z","shell.execute_reply.started":"2025-05-09T11:28:46.963083Z","shell.execute_reply":"2025-05-09T11:28:50.49728Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for col in  ['Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp', 'Calories']:\n    plt.figure()\n    sns.boxplot(x=train[col])\n    plt.title(f'boxplot - {col}' )\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T11:28:53.146876Z","iopub.execute_input":"2025-05-09T11:28:53.147222Z","iopub.status.idle":"2025-05-09T11:28:53.965108Z","shell.execute_reply.started":"2025-05-09T11:28:53.147197Z","shell.execute_reply":"2025-05-09T11:28:53.964311Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def remove_outliers_iqr(df, columns, threshold=1.5):\n    \"\"\"\n    Removes outliers from specified columns using the IQR method.\n    \n    Parameters:\n        df (pd.DataFrame): Input DataFrame.\n        columns (list): List of column names to process.\n        threshold (float): Multiplier for IQR (default: 1.5). Higher = stricter outlier removal.\n    \n    Returns:\n        pd.DataFrame: DataFrame with outliers removed (rows dropped).\n    \"\"\"\n    df_clean = df.copy()\n    for col in columns:\n        # Calculate Q1, Q3, and IQR\n        Q1 = df_clean[col].quantile(0.25)\n        Q3 = df_clean[col].quantile(0.75)\n        IQR = Q3 - Q1\n        \n        # Define bounds\n        lower_bound = Q1 - threshold * IQR\n        upper_bound = Q3 + threshold * IQR\n        \n        # Filter rows within bounds\n        df_clean = df_clean[(df_clean[col] >= lower_bound) & (df_clean[col] <= upper_bound)]\n    \n    return df_clean.reset_index(drop=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T13:15:53.84155Z","iopub.execute_input":"2025-05-09T13:15:53.841903Z","iopub.status.idle":"2025-05-09T13:15:53.848951Z","shell.execute_reply.started":"2025-05-09T13:15:53.84184Z","shell.execute_reply":"2025-05-09T13:15:53.84765Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#train_clean = remove_outliers_iqr(train, ['Height', 'Weight', 'Heart_Rate', 'Body_Temp', 'Calories'], threshold=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T13:15:55.747299Z","iopub.execute_input":"2025-05-09T13:15:55.747746Z","iopub.status.idle":"2025-05-09T13:15:56.192831Z","shell.execute_reply.started":"2025-05-09T13:15:55.747718Z","shell.execute_reply":"2025-05-09T13:15:56.19193Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''#### for col in  ['Height', 'Weight', 'Heart_Rate', 'Body_Temp', 'Calories']:\n    plt.figure()\n    sns.boxplot(x=train_clean[col])\n    plt.title(f'boxplot - {col}' )\n    plt.show()'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T11:29:02.188032Z","iopub.execute_input":"2025-05-09T11:29:02.188808Z","iopub.status.idle":"2025-05-09T11:29:02.846875Z","shell.execute_reply.started":"2025-05-09T11:29:02.188775Z","shell.execute_reply":"2025-05-09T11:29:02.84601Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Correlation heatmap\ncorr = train[['Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp','Calories']].corr()\nsns.heatmap(corr, annot=True, cmap='coolwarm')\nplt.title(\"Correlation Matrix\")\nplt.show()\n\n# Top correlations with target\n\nprint(\"Top Correlations with Listening_Time_minutes:\")\nprint(corr['Calories'].sort_values(ascending=False))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T11:29:19.780861Z","iopub.execute_input":"2025-05-09T11:29:19.7816Z","iopub.status.idle":"2025-05-09T11:29:20.254322Z","shell.execute_reply.started":"2025-05-09T11:29:19.781573Z","shell.execute_reply":"2025-05-09T11:29:20.253476Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df = train.copy()\n\nX = train_df.drop(columns=['Calories'])\ny = train_df['Calories']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n#numeric_features = list(X.select_dtypes(include=['float64']).columns).drop(['time_cos','time_sin', 'day_cos', 'day_sin'])\n\nnumeric_features = X.select_dtypes(include=['float64', 'int64']).columns\ncategorical_features = X.select_dtypes(include=['object', 'category']).columns\n\n\n\nnumeric_transformer = Pipeline(steps=[\n    ('scaler', StandardScaler()),\n    ('poly', PolynomialFeatures(degree=2, include_bias=False))\n])\n\ncategorical_transformer = Pipeline(steps=[\n    ('onehot', OneHotEncoder())\n])\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numeric_transformer, numeric_features),\n        ('cat', categorical_transformer, categorical_features)\n    ]\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T15:14:22.011576Z","iopub.execute_input":"2025-05-09T15:14:22.011911Z","iopub.status.idle":"2025-05-09T15:14:22.286056Z","shell.execute_reply.started":"2025-05-09T15:14:22.011886Z","shell.execute_reply":"2025-05-09T15:14:22.284875Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## GradientBoostingRegressor","metadata":{}},{"cell_type":"code","source":"'''model = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n  ('regressor',  GradientBoostingRegressor(min_samples_leaf=5))\n])\n\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\ny_pred = np.maximum(y_pred, 0)\n\n#model.fit(X_train, np.log1p(y_train))\n#y_pred = np.expm1(model.predict(X_test)) import xgboost as xgb\n\nrmse = np.sqrt(mean_squared_error(y_test, y_pred))\n\n\nprint(f\"Baseline RMSE: {rmse:.4f}\")\nprint(f\"MAE: {mean_absolute_error(y_test, y_pred):.2f}\")\nprint(f\"RÂ²: {r2_score(y_test, y_pred):.2f}\")\nprint(f\"RMSLE: {np.sqrt(mean_squared_log_error(y_test, y_pred)):.4f}\")'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T13:47:54.988761Z","iopub.execute_input":"2025-05-09T13:47:54.989181Z","iopub.status.idle":"2025-05-09T13:47:54.995667Z","shell.execute_reply.started":"2025-05-09T13:47:54.989156Z","shell.execute_reply":"2025-05-09T13:47:54.994693Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import xgboost as xgb","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n  ('regressor',  GradientBoostingRegressor(min_samples_leaf=5))\n])\n\n#model.fit(X_train, y_train)\n#y_pred = model.predict(X_test)\n#y_pred = np.maximum(y_pred, 0)\n\nmodel.fit(X_train, np.log1p(y_train))\ny_pred = np.expm1(model.predict(X_test)) \n\nrmse = np.sqrt(mean_squared_error(y_test, y_pred))\n\n\nprint(f\"Baseline RMSE: {rmse:.4f}\")\nprint(f\"MAE: {mean_absolute_error(y_test, y_pred):.2f}\")\nprint(f\"RÂ²: {r2_score(y_test, y_pred):.2f}\")\nprint(f\"RMSLE: {np.sqrt(mean_squared_log_error(y_test, y_pred)):.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T15:37:28.098465Z","iopub.execute_input":"2025-05-09T15:37:28.098869Z","iopub.status.idle":"2025-05-09T15:43:35.081063Z","shell.execute_reply.started":"2025-05-09T15:37:28.098832Z","shell.execute_reply":"2025-05-09T15:43:35.079889Z"}},"outputs":[{"name":"stdout","text":"Baseline RMSE: 4.8109\nMAE: 2.94\nRÂ²: 0.99\nRMSLE: 0.0697\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"## StackingRegressor","metadata":{}},{"cell_type":"code","source":"base_models = [\n    ('gb', GradientBoostingRegressor(min_samples_leaf=5)),\n    ('rf', RandomForestRegressor(max_samples=100000, n_estimators=50, min_samples_leaf=100))\n]\n\n\nmeta_model = LinearRegression()\n\n\nstack = StackingRegressor(\n    estimators=base_models,\n    final_estimator=meta_model,\n    cv=5, \n    n_jobs=-1\n)\n\nmodel = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n  ('regressor',  stack)\n])\n\n\n#model.fit(X_train, y_train)\n#y_pred = model.predict(X_test)\n#y_pred = np.maximum(y_pred, 0)\n\nmodel.fit(X_train, np.log1p(y_train))\ny_pred = np.expm1(model.predict(X_test)) \n\nrmse = np.sqrt(mean_squared_error(y_test, y_pred))\n\n\nprint(f\"Baseline RMSE: {rmse:.4f}\")\nprint(f\"MAE: {mean_absolute_error(y_test, y_pred):.2f}\")\nprint(f\"RÂ²: {r2_score(y_test, y_pred):.2f}\")\nprint(f\"RMSLE: {np.sqrt(mean_squared_log_error(y_test, y_pred)):.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T15:14:27.914007Z","iopub.execute_input":"2025-05-09T15:14:27.91436Z","iopub.status.idle":"2025-05-09T15:36:24.81826Z","shell.execute_reply.started":"2025-05-09T15:14:27.914323Z","shell.execute_reply":"2025-05-09T15:36:24.816944Z"}},"outputs":[{"name":"stdout","text":"Baseline RMSE: 4.4990\nMAE: 2.71\nRÂ²: 0.99\nRMSLE: 0.0677\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"plt.scatter(y_test, y_pred)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def create_kaggle_submission(\n    pipeline,  # Your sklearn Pipeline (includes preprocessor + model)\n    test_data,  # test data\n    sample_sub,  # Kaggle's sample submission\n    output_file=\"submission.csv\",  # Output filename\n    id_column=\"id\",  # Name of ID column (e.g., 'PassengerId', 'Id')\n    target_column=\"SalePrice\"  # Name of target column (e.g., 'Survived')\n):\n    \"\"\"\n    Creates a Kaggle submission file using a pre-fitted sklearn Pipeline.\n    \n    Args:\n        pipeline: Fitted sklearn Pipeline (preprocessor + model).\n        test_file_path (str): Path to test data CSV.\n        sample_submission_path (str): Path to sample submission CSV.\n        output_file (str): Output submission filename.\n        id_column (str): Name of the ID column in test data.\n        target_column (str): Name of the target column in sample submission.\n    \"\"\"\n\n    \n    # Ensure ID column is preserved\n    ids = test_data[id_column]\n    \n    # Drop ID column (if it exists in features) to avoid preprocessing issues\n    if id_column in test_data.columns:\n        test_features = test_data.drop(columns=[id_column])\n    else:\n        test_features = test_data\n    \n    # Predict using the pipeline (auto-applies preprocessing)\n    predictions = pipeline.predict(test_features)\n    \n    # Format predictions to match sample submission\n    \n    #sample_sub[target_column] = predictions\n    sample_sub[target_column] = np.expm1(predictions)\n    #sample_sub[target_column] = np.maximum(predictions, 0)\n    \n    # Save to CSV\n    sample_sub.to_csv(output_file, index=False)\n    print(f\"âœ… Submission file saved as '{output_file}'\")\n    print(f\"ðŸ“Š Sample submission head:\\n{sample_sub.head()}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"create_kaggle_submission(\n    pipeline=model,\n    test_data=test,\n    sample_sub=submission,\n    output_file='/kaggle/working/submission.csv',\n    id_column=\"id\",  # Adjust for your competition\n    target_column=\"Calories\"  # Adjust for your competition\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}